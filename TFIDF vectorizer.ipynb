{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/13632/Downloads/dataset_stance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perceptron_tagger: HTTP Error 401:\n",
      "[nltk_data]     Unauthorized\n",
      "[nltk_data] Error loading stopwords: HTTP Error 401: Unauthorized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Could not fetch URL https://pypi.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))) - skipping\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Directory 'C:/Users/13632/AppData/Roaming/nltk_data/corpora/averaged_perceptron_tagger' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install \"C:/Users/13632/AppData/Roaming/nltk_data/corpora/averaged_perceptron_tagger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Directory 'C:/Users/13632/AppData/Roaming/nltk_data/corpora/stopwords' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Could not fetch URL https://pypi.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))) - skipping\n"
     ]
    }
   ],
   "source": [
    "pip install \"C:/Users/13632/AppData/Roaming/nltk_data/corpora/stopwords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORDNET LEMMATIZER (with appropriate pos tags)\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "# Define function to lemmatize each word with its POS tag\n",
    " \n",
    "# POS_TAGGER_FUNCTION : TYPE 1\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return None\n",
    " \n",
    "def lemmatizing(data):\n",
    "    lemmatized_data = []\n",
    "    for i in range(len(data)):\n",
    "        sentence = data['Tweet'][i]\n",
    "\n",
    "        # tokenize the sentence and find the POS tag for each token\n",
    "        word_tokens = nltk.wordpunct_tokenize(sentence) #what does wordpunct_tokenize do?\n",
    "        pos_tagged = nltk.pos_tag(word_tokens) \n",
    "\n",
    "        \n",
    "        # As you may have noticed, the above pos tags are a little confusing.\n",
    "        \n",
    "        # we use our own pos_tagger function to make things simpler to understand.\n",
    "        wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "        \n",
    "        lemmatized_sentence = []\n",
    "        for word, tag in wordnet_tagged:\n",
    "            word = word.lower()\n",
    "            if word.isdigit():\n",
    "                del word\n",
    "            elif tag is None:\n",
    "                # if there is no available tag, append the token as is\n",
    "                lemmatized_sentence.append(word)\n",
    "            else:       \n",
    "                # else use the tag to lemmatize the token\n",
    "                lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "        lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "        lemmatized_data.append(lemmatized_sentence)\n",
    "    return lemmatized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no separation based on subtopic\n",
    "def grouping(df):\n",
    "    df_for = []\n",
    "    df_against = []\n",
    "    df_neutral = []\n",
    "    for k in range(len(df)):\n",
    "        if df['Stance'][k] == 'FAVOR':\n",
    "            df_for.append(df['Tweet'][k]) \n",
    "        elif df['Stance'][k] == 'AGAINST':\n",
    "            df_against.append(df['Tweet'][k])\n",
    "        else:\n",
    "            df_neutral.append(df['Tweet'][k])\n",
    "    return df_for, df_against, df_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['Target'])\n",
    "df_atheism = grouped_df.get_group('Atheism')\n",
    "df_climate = grouped_df.get_group('Climate Change is a Real Concern')\n",
    "df_trump = grouped_df.get_group('Donald Trump')\n",
    "df_feminist = grouped_df.get_group('Feminist Movement')\n",
    "df_clinton = grouped_df.get_group('Hillary Clinton')\n",
    "df_abortion = grouped_df.get_group('Legalization of Abortion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider how to count punctuation too. are they considered by the vectorizer function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidfVectorizer\n",
    "def tfidf_vectorizer(list):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "    matrix = vectorizer.fit_transform(list)\n",
    "    idf_table = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    return idf_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atheism = df_atheism.drop('Unnamed: 0', axis='columns')\n",
    "df_atheism = df_atheism.reset_index()\n",
    "df_atheism = df_atheism.drop('index', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_tweets = lemmatizing(df_atheism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tfidf_vectorizer(lemmatized_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100aeuassembly</th>\n",
       "      <th>100aeuassembly celebrate</th>\n",
       "      <th>100aeuassembly celebrate ethicalunion</th>\n",
       "      <th>100aeuassembly semst</th>\n",
       "      <th>100th</th>\n",
       "      <th>100th anniversary</th>\n",
       "      <th>100th anniversary amazing</th>\n",
       "      <th>10x</th>\n",
       "      <th>10x bad</th>\n",
       "      <th>10x bad bethankful</th>\n",
       "      <th>...</th>\n",
       "      <th>zealot from</th>\n",
       "      <th>zealot from take</th>\n",
       "      <th>zealot lovewins</th>\n",
       "      <th>zealot lovewins semst</th>\n",
       "      <th>zmanoj</th>\n",
       "      <th>zmanoj sanghparivarorg</th>\n",
       "      <th>zmanoj sanghparivarorg when</th>\n",
       "      <th>zubair</th>\n",
       "      <th>zubair ibn</th>\n",
       "      <th>zubair ibn awwam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>733 rows × 22647 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     100aeuassembly  100aeuassembly celebrate  \\\n",
       "0               0.0                       0.0   \n",
       "1               0.0                       0.0   \n",
       "2               0.0                       0.0   \n",
       "3               0.0                       0.0   \n",
       "4               0.0                       0.0   \n",
       "..              ...                       ...   \n",
       "728             0.0                       0.0   \n",
       "729             0.0                       0.0   \n",
       "730             0.0                       0.0   \n",
       "731             0.0                       0.0   \n",
       "732             0.0                       0.0   \n",
       "\n",
       "     100aeuassembly celebrate ethicalunion  100aeuassembly semst  100th  \\\n",
       "0                                      0.0                   0.0    0.0   \n",
       "1                                      0.0                   0.0    0.0   \n",
       "2                                      0.0                   0.0    0.0   \n",
       "3                                      0.0                   0.0    0.0   \n",
       "4                                      0.0                   0.0    0.0   \n",
       "..                                     ...                   ...    ...   \n",
       "728                                    0.0                   0.0    0.0   \n",
       "729                                    0.0                   0.0    0.0   \n",
       "730                                    0.0                   0.0    0.0   \n",
       "731                                    0.0                   0.0    0.0   \n",
       "732                                    0.0                   0.0    0.0   \n",
       "\n",
       "     100th anniversary  100th anniversary amazing  10x  10x bad  \\\n",
       "0                  0.0                        0.0  0.0      0.0   \n",
       "1                  0.0                        0.0  0.0      0.0   \n",
       "2                  0.0                        0.0  0.0      0.0   \n",
       "3                  0.0                        0.0  0.0      0.0   \n",
       "4                  0.0                        0.0  0.0      0.0   \n",
       "..                 ...                        ...  ...      ...   \n",
       "728                0.0                        0.0  0.0      0.0   \n",
       "729                0.0                        0.0  0.0      0.0   \n",
       "730                0.0                        0.0  0.0      0.0   \n",
       "731                0.0                        0.0  0.0      0.0   \n",
       "732                0.0                        0.0  0.0      0.0   \n",
       "\n",
       "     10x bad bethankful  ...  zealot from  zealot from take  zealot lovewins  \\\n",
       "0                   0.0  ...          0.0               0.0              0.0   \n",
       "1                   0.0  ...          0.0               0.0              0.0   \n",
       "2                   0.0  ...          0.0               0.0              0.0   \n",
       "3                   0.0  ...          0.0               0.0              0.0   \n",
       "4                   0.0  ...          0.0               0.0              0.0   \n",
       "..                  ...  ...          ...               ...              ...   \n",
       "728                 0.0  ...          0.0               0.0              0.0   \n",
       "729                 0.0  ...          0.0               0.0              0.0   \n",
       "730                 0.0  ...          0.0               0.0              0.0   \n",
       "731                 0.0  ...          0.0               0.0              0.0   \n",
       "732                 0.0  ...          0.0               0.0              0.0   \n",
       "\n",
       "     zealot lovewins semst  zmanoj  zmanoj sanghparivarorg  \\\n",
       "0                      0.0     0.0                     0.0   \n",
       "1                      0.0     0.0                     0.0   \n",
       "2                      0.0     0.0                     0.0   \n",
       "3                      0.0     0.0                     0.0   \n",
       "4                      0.0     0.0                     0.0   \n",
       "..                     ...     ...                     ...   \n",
       "728                    0.0     0.0                     0.0   \n",
       "729                    0.0     0.0                     0.0   \n",
       "730                    0.0     0.0                     0.0   \n",
       "731                    0.0     0.0                     0.0   \n",
       "732                    0.0     0.0                     0.0   \n",
       "\n",
       "     zmanoj sanghparivarorg when  zubair  zubair ibn  zubair ibn awwam  \n",
       "0                            0.0     0.0         0.0               0.0  \n",
       "1                            0.0     0.0         0.0               0.0  \n",
       "2                            0.0     0.0         0.0               0.0  \n",
       "3                            0.0     0.0         0.0               0.0  \n",
       "4                            0.0     0.0         0.0               0.0  \n",
       "..                           ...     ...         ...               ...  \n",
       "728                          0.0     0.0         0.0               0.0  \n",
       "729                          0.0     0.0         0.0               0.0  \n",
       "730                          0.0     0.0         0.0               0.0  \n",
       "731                          0.0     0.0         0.0               0.0  \n",
       "732                          0.0     0.0         0.0               0.0  \n",
       "\n",
       "[733 rows x 22647 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table.transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
